version: '3.3'

services:
  cuda:
    image: ubuntu-cuda:v${CUDA_VERSION}
    build:
      context: ./dockerfiles/nvidia/v${CUDA_VERSION}
      dockerfile: Dockerfile
      args:
        - CUDA_VERSION=${CUDA_VERSION}
        - CUDNN_VERSION=${CUDNN_VERSION}
        - UBUNTU_VERSION=20.04

  ssh:
    depends_on:
      - cuda
    image: ubuntu-ssh:v1
    build:
      context: ./dockerfiles/ssh
      dockerfile: Dockerfile
      args:
        - IMAGE=ubuntu-cuda
        - TAG=v${CUDA_VERSION}

  pytorch:
    depends_on:
      - ssh
    image: pytorch:v${PYTORCH_VERSION}
    build:
      context: ./dockerfiles/pytorch/v${PYTORCH_VERSION}
      dockerfile: Dockerfile
      args:
        - IMAGE=ubuntu-ssh
        - TAG=v1
        - CUDA_WITHOUT_PATCH_VERSION=${CUDA_WITHOUT_PATCH_VERSION}

  publish:
    depends_on:
      - pytorch
    image: ${BACKEND_IMAGE_NAME}
    container_name: ${BACKEND_CONTAINER_NAME}
    hostname: ${BACKEND_CONTAINER_NAME}
    command: flask run -p 5001
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 0
              capabilities: [gpu]
    shm_size: ${MEMORY_SIZE_GB}GB
    build:
      context: ./dockerfiles/publish
      dockerfile: Dockerfile
      args:
        - IMAGE=pytorch
        - TAG=v${PYTORCH_VERSION}
    ports:
      - '${DEVELOP_SSH_PORT}:22'
      - '${DEVELOP_API_PORT}:5001'